"""å½¢æ…‹ç´ è§£æã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ†ã‚¹ãƒˆ

MorphologicalAnalyzerã‚¯ãƒ©ã‚¹ã®å„æ©Ÿèƒ½ã‚’ç¶²ç¾…çš„ã«ãƒ†ã‚¹ãƒˆã™ã‚‹
"""

import pytest

from app.services.morphological import MorphologicalAnalyzer, Word


class TestWord:
    """Wordãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""

    def test_create_instance(self) -> None:
        """ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ"""
        word = Word(
            surface="èµ°ã‚‹",
            base_form="èµ°ã‚‹",
            part_of_speech="å‹•è©",
            part_of_speech_detail1="è‡ªç«‹",
            part_of_speech_detail2="*",
            part_of_speech_detail3="*",
        )
        assert word.surface == "èµ°ã‚‹"
        assert word.base_form == "èµ°ã‚‹"
        assert word.part_of_speech == "å‹•è©"


class TestMorphologicalAnalyzer:
    """MorphologicalAnalyzerã‚¯ãƒ©ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""

    def test_analyze_simple_sentence(self) -> None:
        """ã‚·ãƒ³ãƒ—ãƒ«ãªæ—¥æœ¬èªæ–‡ã®è§£æãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer()
        words = analyzer.analyze("ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™")

        assert len(words) > 0
        # åè©ã€Œå¤©æ°—ã€ã€å½¢å®¹è©ã€Œè‰¯ã„ã€ãŒæŠ½å‡ºã•ã‚Œã‚‹ã¯ãšï¼ˆã€Œä»Šæ—¥ã€ã¯ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ï¼‰
        surfaces = [w.surface for w in words]
        assert "è‰¯ã„" in surfaces  # å½¢å®¹è©
        assert "å¤©æ°—" in surfaces  # åè©

    def test_analyze_with_various_pos(self) -> None:
        """æ§˜ã€…ãªå“è©ã‚’å«ã‚€æ–‡ã®è§£æãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer()
        words = analyzer.analyze("ç¾ã—ã„èŠ±ãŒé™ã‹ã«å’²ã„ã¦ã„ã‚‹")

        # å“è©ã®ç¢ºèªï¼ˆå‹•è©ã€Œå’²ã„ã¦ã€ã€å‰¯è©ã€Œé™ã‹ã«ã€ã¯é™¤å¤–ã•ã‚Œã‚‹ï¼‰
        pos_list = [w.part_of_speech for w in words]
        assert "å½¢å®¹è©" in pos_list  # ç¾ã—ã„
        assert "åè©" in pos_list  # èŠ±ã€é™ã‹ï¼ˆå½¢å®¹å‹•è©èªå¹¹ï¼‰
        assert "å‹•è©" not in pos_list  # å‹•è©ã¯é™¤å¤–ã•ã‚Œã‚‹

    def test_analyze_empty_string(self) -> None:
        """ç©ºæ–‡å­—åˆ—ã®è§£æãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer()
        words = analyzer.analyze("")

        assert len(words) == 0

    def test_analyze_whitespace_only(self) -> None:
        """ç©ºç™½ã®ã¿ã®æ–‡å­—åˆ—ã®è§£æãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer()
        words = analyzer.analyze("   \n\t  ")

        assert len(words) == 0

    def test_analyze_symbols_only(self) -> None:
        """è¨˜å·ã®ã¿ã®æ–‡å­—åˆ—ã®è§£æãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer()
        words = analyzer.analyze("ï¼ï¼Ÿï¼ ï¼ƒï¼„ï¼…")

        # MeCabã®è¾æ›¸ã«ã‚ˆã£ã¦ã¯è¨˜å·ã‚’åè©ã¨ã—ã¦è§£æã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹
        # å°‘ãªãã¨ã‚‚ã‚¨ãƒ©ãƒ¼ã«ãªã‚‰ãªã„ã“ã¨ã‚’ç¢ºèª
        assert isinstance(words, list)

    def test_analyze_mixed_japanese_english(self) -> None:
        """æ—¥è‹±æ··åœ¨ãƒ†ã‚­ã‚¹ãƒˆã®è§£æãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer()
        words = analyzer.analyze("ä»Šæ—¥ã¯Pythonã§ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã™ã‚‹")

        surfaces = [w.surface for w in words]
        # ã€Œä»Šæ—¥ã€ã¯ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã€å‹•è©ã€Œã™ã‚‹ã€ã‚‚é™¤å¤–ã•ã‚Œã‚‹
        # ã€ŒPythonã€ã‚‚ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã®ã¿ãªã®ã§é™¤å¤–ã•ã‚Œã‚‹ã‹ã‚‚
        assert "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°" in surfaces
        assert "Python" in surfaces or "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°" in surfaces

    def test_analyze_with_numbers(self) -> None:
        """æ•°å­—ã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆã®è§£æãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer()
        words = analyzer.analyze("æ˜æ—¥ã¯10æ™‚ã«é›†åˆã§ã™")

        # æ•°è©ã¯é™¤å¤–ã•ã‚Œã‚‹ã¯ãšï¼ˆã€Œæ˜æ—¥ã€ã‚‚ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ï¼‰
        surfaces = [w.surface for w in words]
        assert "é›†åˆ" in surfaces  # åè©
        assert "10" not in surfaces  # æ•°è©ã¯é™¤å¤–

    def test_min_length_filtering(self) -> None:
        """æœ€å°æ–‡å­—æ•°ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(min_length=2)
        words = analyzer.analyze("ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™")

        # 1æ–‡å­—ã®å˜èªã¯é™¤å¤–ã•ã‚Œã‚‹
        for word in words:
            assert len(word.surface) >= 2

    def test_exclude_specific_pos(self) -> None:
        """ç‰¹å®šå“è©ã®é™¤å¤–ãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(exclude_parts=["å‹•è©"])
        words = analyzer.analyze("ç¾ã—ã„èŠ±ãŒå’²ã„ã¦ã„ã‚‹")

        # å‹•è©ã¯é™¤å¤–ã•ã‚Œã‚‹ã¯ãš
        pos_list = [w.part_of_speech for w in words]
        assert "å‹•è©" not in pos_list
        assert "å½¢å®¹è©" in pos_list  # å½¢å®¹è©ã¯æ®‹ã‚‹
        assert "åè©" in pos_list  # åè©ã¯æ®‹ã‚‹

    def test_exclude_multiple_pos(self) -> None:
        """è¤‡æ•°å“è©ã®é™¤å¤–ãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(exclude_parts=["å‹•è©", "å½¢å®¹è©"])
        words = analyzer.analyze("ç¾ã—ã„èŠ±ãŒé™ã‹ã«å’²ã„ã¦ã„ã‚‹")

        pos_list = [w.part_of_speech for w in words]
        assert "å‹•è©" not in pos_list
        assert "å½¢å®¹è©" not in pos_list
        assert "åè©" in pos_list  # åè©ã¯æ®‹ã‚‹
        # ã€Œé™ã‹ã«ã€ã¯å½¢å®¹å‹•è©èªå¹¹ã¨ã—ã¦åè©ã«åˆ†é¡ã•ã‚Œã‚‹

    def test_exclude_parts_with_set(self) -> None:
        """é™¤å¤–å“è©ã«setã‚’æ¸¡ã™ãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(exclude_parts={"å‹•è©", "å½¢å®¹è©"})
        words = analyzer.analyze("ç¾ã—ã„èŠ±ãŒå’²ã„ã¦ã„ã‚‹")

        pos_list = [w.part_of_speech for w in words]
        assert "å‹•è©" not in pos_list
        assert "å½¢å®¹è©" not in pos_list
        assert "åè©" in pos_list  # åè©ã¯æ®‹ã‚‹

    def test_filter_non_independent_noun(self) -> None:
        """éè‡ªç«‹åè©ã®é™¤å¤–ãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer()
        words = analyzer.analyze("èµ°ã‚‹ã“ã¨ãŒå¥½ãã§ã™")

        surfaces = [w.surface for w in words]
        # éè‡ªç«‹åè©ã€Œã“ã¨ã€ã¯é™¤å¤–ã•ã‚Œã‚‹
        assert "ã“ã¨" not in surfaces

    def test_filter_pronoun(self) -> None:
        """ä»£åè©ã®é™¤å¤–ãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer()
        words = analyzer.analyze("ã“ã‚Œã¯ãƒšãƒ³ã§ã™")

        surfaces = [w.surface for w in words]
        # ä»£åè©ã€Œã“ã‚Œã€ã¯é™¤å¤–ã•ã‚Œã‚‹
        assert "ã“ã‚Œ" not in surfaces
        # ä¸€èˆ¬åè©ã€Œãƒšãƒ³ã€ã¯æ®‹ã‚‹
        assert "ãƒšãƒ³" in surfaces

    def test_extract_interjection(self) -> None:
        """æ„Ÿå‹•è©ã®æŠ½å‡ºãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer()
        words = analyzer.analyze("ã‚ãƒ¼ã‚ç–²ã‚ŒãŸãªãƒ¼")

        # MeCabã®è¾æ›¸ã«ã‚ˆã£ã¦çµæœãŒç•°ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€
        # å°‘ãªãã¨ã‚‚ä½•ã‹ãŒæŠ½å‡ºã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert len(words) > 0

    def test_base_form_extraction(self) -> None:
        """åŸºæœ¬å½¢ã®æŠ½å‡ºãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer()
        words = analyzer.analyze("èµ°ã£ã¦ã„ã‚‹")

        # å‹•è©ã®åŸºæœ¬å½¢ãŒæŠ½å‡ºã•ã‚Œã‚‹ã‹ç¢ºèª
        for word in words:
            if word.part_of_speech == "å‹•è©" and word.surface in ["èµ°ã£", "èµ°ã‚‹"]:
                assert word.base_form == "èµ°ã‚‹"

    def test_multiple_sentences(self) -> None:
        """è¤‡æ•°æ–‡ã®è§£æãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer()
        words = analyzer.analyze("ä»Šæ—¥ã¯æ™´ã‚Œã§ã™ã€‚æ˜æ—¥ã¯é›¨ã§ã™ã€‚")

        # ä¸¡æ–¹ã®æ–‡ã‹ã‚‰å˜èªãŒæŠ½å‡ºã•ã‚Œã‚‹ï¼ˆã€Œä»Šæ—¥ã€ã€Œæ˜æ—¥ã€ã¯ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ï¼‰
        surfaces = [w.surface for w in words]
        assert "æ™´ã‚Œ" in surfaces
        assert "é›¨" in surfaces

    def test_long_text(self) -> None:
        """é•·æ–‡ã®è§£æãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer()
        long_text = "ä»Šæ—¥ã¯å¤©æ°—ãŒè‰¯ã„ã®ã§å…¬åœ’ã«è¡Œãã¾ã—ãŸã€‚" * 10
        words = analyzer.analyze(long_text)

        # é©åˆ‡ã«è§£æã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆã€Œä»Šæ—¥ã€ã¯ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã€å‹•è©ã¯é™¤å¤–ï¼‰
        assert len(words) > 0
        surfaces = [w.surface for w in words]
        assert "å¤©æ°—" in surfaces
        assert "è‰¯ã„" in surfaces
        assert "å…¬åœ’" in surfaces

    def test_mecab_initialization_error(self) -> None:
        """MeCabåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
        # ã“ã®ãƒ†ã‚¹ãƒˆã¯å®Ÿéš›ã®ã‚¨ãƒ©ãƒ¼ã‚’å†ç¾ã™ã‚‹ã®ãŒé›£ã—ã„ãŸã‚ã€
        # æ­£å¸¸ã«åˆæœŸåŒ–ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª
        try:
            analyzer = MorphologicalAnalyzer()
            assert analyzer.tagger is not None
        except RuntimeError:
            pytest.fail("MeCabã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")


class TestConsecutiveNounCombination:
    """é€£ç¶šåè©çµåˆæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""

    def test_combine_two_nouns(self) -> None:
        """2ã¤ã®åè©ãŒé€£ç¶šã™ã‚‹å ´åˆã®çµåˆãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        words = analyzer.analyze("æ©Ÿå‹•æˆ¦å£«")

        # ã€Œæ©Ÿå‹•ã€ã€Œæˆ¦å£«ã€ãŒã€Œæ©Ÿå‹•æˆ¦å£«ã€ã¨ã—ã¦çµåˆã•ã‚Œã‚‹ã¹ã
        surfaces = [w.surface for w in words]
        assert "æ©Ÿå‹•æˆ¦å£«" in surfaces
        assert "æ©Ÿå‹•" not in surfaces
        assert "æˆ¦å£«" not in surfaces

    def test_combine_three_or_more_nouns(self) -> None:
        """3ã¤ä»¥ä¸Šã®åè©ãŒé€£ç¶šã™ã‚‹å ´åˆã®çµåˆãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        words = analyzer.analyze("æ©Ÿå‹•æˆ¦å£«ã‚¬ãƒ³ãƒ€ãƒ ")

        # ã€Œæ©Ÿå‹•ã€ã€Œæˆ¦å£«ã€ã€Œã‚¬ãƒ³ãƒ€ãƒ ã€ãŒã€Œæ©Ÿå‹•æˆ¦å£«ã‚¬ãƒ³ãƒ€ãƒ ã€ã¨ã—ã¦çµåˆã•ã‚Œã‚‹ã¹ã
        surfaces = [w.surface for w in words]
        assert "æ©Ÿå‹•æˆ¦å£«ã‚¬ãƒ³ãƒ€ãƒ " in surfaces or "æ©Ÿå‹•æˆ¦å£«" in surfaces  # è¾æ›¸æ¬¡ç¬¬ã§å¤‰ã‚ã‚‹å¯èƒ½æ€§
        # å°‘ãªãã¨ã‚‚åˆ†å‰²ã•ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª
        word_count = len([w for w in words if w.part_of_speech == "åè©"])
        assert word_count <= 2  # å®Œå…¨çµåˆãªã‚‰1ã€éƒ¨åˆ†çµåˆãªã‚‰2

    def test_multiple_noun_groups(self) -> None:
        """è¤‡æ•°ã®é€£ç¶šåè©ã‚°ãƒ«ãƒ¼ãƒ—ãŒç‹¬ç«‹ã—ã¦å‡¦ç†ã•ã‚Œã‚‹ãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        words = analyzer.analyze("æ©Ÿå‹•æˆ¦å£«ã®ãƒ—ãƒ©ãƒ¢ãƒ‡ãƒ«")

        # ã€Œæ©Ÿå‹•æˆ¦å£«ã€ã¨ã€Œãƒ—ãƒ©ãƒ¢ãƒ‡ãƒ«ã€ãŒç‹¬ç«‹ã—ã¦å­˜åœ¨ã™ã¹ã
        surfaces = [w.surface for w in words]
        # ã€Œæ©Ÿå‹•æˆ¦å£«ã€ã¾ãŸã¯ã€Œæ©Ÿå‹•ã€ã€Œæˆ¦å£«ã€ã®ã„ãšã‚Œã‹
        # ã€Œãƒ—ãƒ©ãƒ¢ãƒ‡ãƒ«ã€ã¯çµåˆã•ã‚Œãªã„ï¼ˆã™ã§ã«1å˜èªï¼‰
        assert "ãƒ—ãƒ©ãƒ¢ãƒ‡ãƒ«" in surfaces or "ãƒ—ãƒ©ãƒ¢" in surfaces

    def test_single_char_noun_combination(self) -> None:
        """1æ–‡å­—åè©ã®é€£ç¶šçµåˆãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        # ã€ŒãŠèŒ¶ã€ã¯è¾æ›¸ã«ã‚ˆã£ã¦ã¯æ—¢ã«1å˜èªã¨ã—ã¦èªè­˜ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹
        words = analyzer.analyze("ãŠèŒ¶ã‚’é£²ã‚€")

        surfaces = [w.surface for w in words]
        # ã€ŒãŠã€ã¨ã€ŒèŒ¶ã€ãŒçµåˆã•ã‚Œã‚‹ã‹ã€æ—¢ã«ã€ŒãŠèŒ¶ã€ã¨ã—ã¦èªè­˜ã•ã‚Œã‚‹
        assert "ãŠèŒ¶" in surfaces or "èŒ¶" in surfaces

    def test_nouns_separated_by_particle(self) -> None:
        """åŠ©è©ã§åŒºåˆ‡ã‚‰ã‚ŒãŸåè©ã¯çµåˆã•ã‚Œãªã„ãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        words = analyzer.analyze("ã‚¬ãƒ³ãƒ€ãƒ ã®ãƒ—ãƒ©ãƒ¢ãƒ‡ãƒ«")

        surfaces = [w.surface for w in words]
        # ã€Œã‚¬ãƒ³ãƒ€ãƒ ã®ãƒ—ãƒ©ãƒ¢ãƒ‡ãƒ«ã€ã¨çµåˆã•ã‚Œã‚‹ã¹ãã§ã¯ãªã„
        # ã€Œã‚¬ãƒ³ãƒ€ãƒ ã€ã¨ã€Œãƒ—ãƒ©ãƒ¢ãƒ‡ãƒ«ã€ãŒå€‹åˆ¥ã«å­˜åœ¨ã™ã‚‹ã‹ã€
        # ã€Œãƒ—ãƒ©ãƒ¢ã€ã€Œãƒ‡ãƒ«ã€ã®ã‚ˆã†ã«åˆ†å‰²ã•ã‚Œã‚‹
        assert "ã‚¬ãƒ³ãƒ€ãƒ ã®ãƒ—ãƒ©ãƒ¢ãƒ‡ãƒ«" not in surfaces
        # åŠ©è©ã€Œã®ã€ã¯é™¤å¤–ã•ã‚Œã‚‹ãŸã‚ã€çµæœã«å«ã¾ã‚Œãªã„

    def test_combined_noun_with_stopwords(self) -> None:
        """é€£ç¶šåè©ãŒã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã«è©²å½“ã™ã‚‹å ´åˆã®é™¤å¤–ãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        # neologdè¾æ›¸ã¯ã€Œä»Šæ—¥ã®å¤©æ°—ã€ã‚’1ã¤ã®å›ºæœ‰åè©ã¨ã—ã¦èªè­˜ã™ã‚‹
        # ãã®ãŸã‚ã€ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã€Œä»Šæ—¥ã€ã«ã‚ˆã‚‹é™¤å¤–ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã«ã¯åˆ¥ã®è¡¨ç¾ãŒå¿…è¦
        words = analyzer.analyze("ä»Šæ—¥ã¯æ™´ã‚Œ")

        surfaces = [w.surface for w in words]
        # ã€Œä»Šæ—¥ã€ã¯ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã®ãŸã‚é™¤å¤–ã•ã‚Œã‚‹ï¼ˆneologdã§ã¯å˜ç‹¬ã§å‡ºç¾ï¼‰
        assert "ä»Šæ—¥" not in surfaces
        # ã€Œæ™´ã‚Œã€ã¯åè©ã¨ã—ã¦æŠ½å‡ºã•ã‚Œã‚‹
        assert any("æ™´ã‚Œ" in s for s in surfaces)

    def test_combined_noun_with_min_length(self) -> None:
        """é€£ç¶šåè©ã¨æœ€å°å˜èªé•·ãƒ•ã‚£ãƒ«ã‚¿ã®çµ„ã¿åˆã‚ã›ãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(min_length=3)
        words = analyzer.analyze("ãŠèŒ¶")

        # ã€ŒãŠã€+ã€ŒèŒ¶ã€=ã€ŒãŠèŒ¶ã€(2æ–‡å­—)ã¯æœ€å°å˜èªé•·3ã«æº€ãŸãªã„ãŸã‚é™¤å¤–ã•ã‚Œã‚‹
        # ã¾ãŸã¯ã€ŒãŠèŒ¶ã€ã¨ã—ã¦èªè­˜ã•ã‚Œã¦ã‚‚2æ–‡å­—ã®ãŸã‚é™¤å¤–
        assert len([w for w in words if "èŒ¶" in w.surface]) == 0

    def test_noun_with_sahen_connection(self) -> None:
        """ã‚µå¤‰æ¥ç¶šåè©ã‚’å«ã‚€é€£ç¶šåè©ã®çµåˆãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        # ã‚µå¤‰æ¥ç¶šåè©ã€Œå‹‰å¼·ã€ã¨åè©ã€Œä¼šã€ãŒé€£ç¶šåè©ã¨ã—ã¦çµåˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        words = analyzer.analyze("å‹‰å¼·ä¼š")

        surfaces = [w.surface for w in words]
        # ã€Œå‹‰å¼·ä¼šã€ãŒ1èªã¨ã—ã¦çµåˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹
        assert "å‹‰å¼·ä¼š" in surfaces

    def test_noun_with_adjective_stem(self) -> None:
        """å½¢å®¹å‹•è©èªå¹¹ã¯çµåˆå¯¾è±¡å¤–ã®ãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        words = analyzer.analyze("ç¶ºéº—ãªèŠ±")

        surfaces = [w.surface for w in words]
        # ã€Œç¶ºéº—ã€ã¯å½¢å®¹å‹•è©èªå¹¹ãªã®ã§ã€ã€ŒèŠ±ã€ã¨çµåˆã•ã‚Œãªã„
        assert "ç¶ºéº—ãªèŠ±" not in surfaces
        assert "èŠ±" in surfaces

    def test_exclude_number_noun(self) -> None:
        """æ•°è©ã¯çµåˆå¯¾è±¡å¤–ã®ãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        # neologdè¾æ›¸ã¯ã€Œ12æ™‚ã€ã‚’å›ºæœ‰åè©ã¨ã—ã¦èªè­˜ã™ã‚‹ãŸã‚ã€åˆ¥ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ä½¿ç”¨
        words = analyzer.analyze("3å€‹è²·ã£ãŸ")

        surfaces = [w.surface for w in words]
        # ã€Œ3ã€ï¼ˆæ•°è©ï¼‰ã¨ã€Œå€‹ã€ï¼ˆæ¥å°¾è¾ï¼‰ã¯çµåˆã•ã‚Œãªã„ã€ã¾ãŸã¯æ•°è©ãŒé™¤å¤–ã•ã‚Œã‚‹
        # neologdã§ã¯ã€Œ3å€‹ã€ãŒå›ºæœ‰åè©ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€çµåˆã•ã‚Œãªã„ã“ã¨ã‚’ç¢ºèª
        # ã“ã“ã§ã¯æ•°è©ãŒé™¤å¤–ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert "3" not in surfaces or len(surfaces) > 0  # æ•°è©ã¯é™¤å¤–ã•ã‚Œã‚‹å¯èƒ½æ€§

    def test_exclude_suffix_noun(self) -> None:
        """æ¥å°¾è¾ã¯çµåˆå¯¾è±¡å¤–ã®ãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        # neologdã§ã¯ã€ŒçŠ¬ã€ï¼ˆä¸€èˆ¬åè©ï¼‰+ã€Œã¡ã‚ƒã‚“ã€ï¼ˆæ¥å°¾è¾ï¼‰ã«åˆ†å‰²ã•ã‚Œã‚‹
        words = analyzer.analyze("çŠ¬ã¡ã‚ƒã‚“")

        surfaces = [w.surface for w in words]
        # ã€ŒçŠ¬ã€ã¨ã€Œã¡ã‚ƒã‚“ã€ã¯çµåˆã•ã‚Œãªã„
        # ã€ŒçŠ¬ã€ã¯ä¸€èˆ¬åè©ã¨ã—ã¦æŠ½å‡ºã•ã‚Œã‚‹
        # ã€Œã¡ã‚ƒã‚“ã€ã¯æ¥å°¾è¾ã®ãŸã‚é™¤å¤–ã•ã‚Œã‚‹
        assert "çŠ¬ã¡ã‚ƒã‚“" not in surfaces  # çµåˆã•ã‚Œãªã„
        assert "çŠ¬" in surfaces  # ã€ŒçŠ¬ã€ã¯æŠ½å‡ºã•ã‚Œã‚‹
        assert "ã¡ã‚ƒã‚“" not in surfaces  # æ¥å°¾è¾ã¯é™¤å¤–ã•ã‚Œã‚‹


class TestEmojiHandling:
    """çµµæ–‡å­—å‡¦ç†ã®ãƒ†ã‚¹ãƒˆ"""

    def test_emoji_not_converted_to_text(self) -> None:
        """çµµæ–‡å­—ãŒãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã•ã‚Œãªã„ãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        words = analyzer.analyze("ä»Šæ—¥ã¯æ¥½ã—ã‹ã£ãŸğŸ˜­")

        # ã€ŒğŸ˜­ã€ã¯ã€Œå¤§æ³£ãã€ãªã©ã®ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã•ã‚Œãšã€çµµæ–‡å­—ã®ã¾ã¾æŠ½å‡ºã•ã‚Œã‚‹
        surfaces = [w.surface for w in words]
        base_forms = [w.base_form for w in words]

        assert "ğŸ˜­" in surfaces  # è¡¨å±¤å½¢ã«çµµæ–‡å­—ãŒå«ã¾ã‚Œã‚‹
        assert "ğŸ˜­" in base_forms  # åŸºæœ¬å½¢ã‚‚çµµæ–‡å­—ã®ã¾ã¾
        assert "å¤§æ³£ã" not in base_forms  # ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã•ã‚Œãªã„
        assert "æ³£ãé¡”" not in base_forms  # ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã•ã‚Œãªã„

    def test_multiple_emojis(self) -> None:
        """è¤‡æ•°ã®çµµæ–‡å­—ãŒæ­£ã—ãæŠ½å‡ºã•ã‚Œã‚‹ãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        words = analyzer.analyze("ğŸ˜­ğŸ˜‚ğŸ˜Š")

        surfaces = [w.surface for w in words]

        # å„çµµæ–‡å­—ãŒå€‹åˆ¥ã«æŠ½å‡ºã•ã‚Œã‚‹
        assert "ğŸ˜­" in surfaces
        assert "ğŸ˜‚" in surfaces
        assert "ğŸ˜Š" in surfaces

    def test_emoji_vs_text(self) -> None:
        """çµµæ–‡å­—ã¨ãƒ†ã‚­ã‚¹ãƒˆãŒåŒºåˆ¥ã•ã‚Œã‚‹ãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(min_length=1)

        # çµµæ–‡å­—ã®ã‚±ãƒ¼ã‚¹
        words_emoji = analyzer.analyze("ğŸ˜­")
        emoji_base_forms = [w.base_form for w in words_emoji]

        # ã€Œæ³£ãé¡”ã€ãƒ†ã‚­ã‚¹ãƒˆã®ã‚±ãƒ¼ã‚¹
        words_text = analyzer.analyze("æ³£ãé¡”")
        text_base_forms = [w.base_form for w in words_text]

        # çµµæ–‡å­—ã¯ã€ŒğŸ˜­ã€ã¨ã—ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆã¯ã€Œæ³£ãé¡”ã€ã¨ã—ã¦åˆ¥ã€…ã«ã‚«ã‚¦ãƒ³ãƒˆã•ã‚Œã‚‹
        assert "ğŸ˜­" in emoji_base_forms
        assert "æ³£ãé¡”" in text_base_forms
        assert "ğŸ˜­" not in text_base_forms
        assert "æ³£ãé¡”" not in emoji_base_forms

    def test_emoji_with_variation_selector(self) -> None:
        """ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒ¬ã‚¯ã‚¿ä»˜ãçµµæ–‡å­—ã®ãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        # ä¸€éƒ¨ã®çµµæ–‡å­—ã¯ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒ¬ã‚¯ã‚¿ï¼ˆU+FE0Fï¼‰ã‚’å«ã‚€
        words = analyzer.analyze("â¤ï¸")  # ãƒãƒ¼ãƒˆãƒãƒ¼ã‚¯ï¼ˆãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒ¬ã‚¯ã‚¿ä»˜ãï¼‰

        if words:  # çµµæ–‡å­—ãŒæŠ½å‡ºã•ã‚Œã‚‹å ´åˆ
            surfaces = [w.surface for w in words]
            base_forms = [w.base_form for w in words]
            # åŸºæœ¬å½¢ã‚‚è¡¨å±¤å½¢ã¨åŒã˜ã«ãªã‚‹
            assert any("â¤" in s for s in surfaces)
            assert any("â¤" in b for b in base_forms)

    def test_emoji_in_sentence(self) -> None:
        """æ–‡ä¸­ã®çµµæ–‡å­—ãŒæ­£ã—ãæŠ½å‡ºã•ã‚Œã‚‹ãƒ†ã‚¹ãƒˆ"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        words = analyzer.analyze("ä»Šæ—¥ã®ãƒ©ã‚¤ãƒ–æœ€é«˜ã ã£ãŸğŸ‰âœ¨")

        surfaces = [w.surface for w in words]
        base_forms = [w.base_form for w in words]

        # é€šå¸¸ã®å˜èªã‚‚æŠ½å‡ºã•ã‚Œã‚‹
        assert any("ãƒ©ã‚¤ãƒ–" in s for s in surfaces)
        assert any("æœ€é«˜" in s for s in surfaces)

        # çµµæ–‡å­—ã‚‚æŠ½å‡ºã•ã‚Œã‚‹
        assert "ğŸ‰" in surfaces
        assert "ğŸ‰" in base_forms  # åŸºæœ¬å½¢ã‚‚çµµæ–‡å­—ã®ã¾ã¾


class TestControlCharacterFiltering:
    """åˆ¶å¾¡æ–‡å­—ã®é™¤å¤–ãƒ†ã‚¹ãƒˆ

    ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒ¬ã‚¯ã‚¿ãªã©ã®åˆ¶å¾¡æ–‡å­—ãŒå˜èªã¨ã—ã¦æŠ½å‡ºã•ã‚Œãªã„ã“ã¨ã‚’ç¢ºèª
    """

    def test_variation_selector_excluded(self) -> None:
        """ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒ¬ã‚¯ã‚¿ï¼ˆU+FE0Fï¼‰ãŒé™¤å¤–ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        # ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒ¬ã‚¯ã‚¿å˜ä½“
        words = analyzer.analyze("\ufe0f")

        surfaces = [w.surface for w in words]

        # ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒ¬ã‚¯ã‚¿ã¯é™¤å¤–ã•ã‚Œã‚‹
        assert "\ufe0f" not in surfaces
        assert len(words) == 0

    def test_zero_width_joiner_excluded(self) -> None:
        """ã‚¼ãƒ­å¹…æ¥åˆå­ï¼ˆU+200Dï¼‰ãŒé™¤å¤–ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        # ã‚¼ãƒ­å¹…æ¥åˆå­å˜ä½“
        words = analyzer.analyze("\u200d")

        surfaces = [w.surface for w in words]

        # ã‚¼ãƒ­å¹…æ¥åˆå­ã¯é™¤å¤–ã•ã‚Œã‚‹
        assert "\u200d" not in surfaces
        assert len(words) == 0

    def test_full_width_space_excluded(self) -> None:
        """å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ï¼ˆU+3000ï¼‰ãŒé™¤å¤–ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        # å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹å˜ä½“
        words = analyzer.analyze("\u3000")

        surfaces = [w.surface for w in words]

        # å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã¯é™¤å¤–ã•ã‚Œã‚‹
        assert "\u3000" not in surfaces
        assert len(words) == 0

    def test_multiple_control_characters_excluded(self) -> None:
        """è¤‡æ•°ã®åˆ¶å¾¡æ–‡å­—ãŒé™¤å¤–ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        # è¤‡æ•°ã®åˆ¶å¾¡æ–‡å­—ã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆ
        words = analyzer.analyze("\ufe0f\u200d\u3000")

        # å…¨ã¦é™¤å¤–ã•ã‚Œã‚‹
        assert len(words) == 0

    def test_control_characters_in_sentence_excluded(self) -> None:
        """æ–‡ä¸­ã®åˆ¶å¾¡æ–‡å­—ãŒé™¤å¤–ã•ã‚Œã€é€šå¸¸ã®å˜èªã¯æŠ½å‡ºã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        # åˆ¶å¾¡æ–‡å­—ã‚’å«ã‚€æ–‡ï¼ˆå®Ÿéš›ã®LINEãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã¯çµµæ–‡å­—ã®å¾Œã«ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒ¬ã‚¯ã‚¿ãŒä»˜ãã“ã¨ãŒã‚ã‚‹ï¼‰
        words = analyzer.analyze("ä»Šæ—¥ã¯\u3000è‰¯ã„\ufe0få¤©æ°—")

        surfaces = [w.surface for w in words]
        base_forms = [w.base_form for w in words]

        # åˆ¶å¾¡æ–‡å­—ã¯é™¤å¤–ã•ã‚Œã‚‹
        assert "\u3000" not in surfaces
        assert "\ufe0f" not in surfaces

        # é€šå¸¸ã®å˜èªã¯æŠ½å‡ºã•ã‚Œã‚‹ï¼ˆåŠ©è©ã€Œã¯ã€ã¯é™¤å¤–ã•ã‚Œã‚‹ï¼‰
        assert "è‰¯ã„" in surfaces or "è‰¯ã„" in base_forms
        assert "å¤©æ°—" in surfaces or "å¤©æ°—" in base_forms

    def test_emoji_extracted_but_variation_selector_excluded(self) -> None:
        """çµµæ–‡å­—ã¯æŠ½å‡ºã•ã‚Œã‚‹ãŒãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒ¬ã‚¯ã‚¿ã¯é™¤å¤–ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        analyzer = MorphologicalAnalyzer(min_length=1)
        # çµµæ–‡å­—ã¨ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒ¬ã‚¯ã‚¿ã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆ
        # å®Ÿéš›ã«ã¯çµµæ–‡å­—ã®ç›´å¾Œã«ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒ¬ã‚¯ã‚¿ãŒæ¥ã‚‹ãŒã€
        # ã“ã“ã§ã¯åˆ†é›¢ã—ã¦ãƒ†ã‚¹ãƒˆ
        words = analyzer.analyze("ğŸ˜­")  # æ³£ãé¡”çµµæ–‡å­—
        words_with_vs = analyzer.analyze("ğŸ˜­\ufe0f")  # æ³£ãé¡”çµµæ–‡å­— + ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒ¬ã‚¯ã‚¿

        surfaces1 = [w.surface for w in words]
        surfaces2 = [w.surface for w in words_with_vs]

        # çµµæ–‡å­—ã¯æŠ½å‡ºã•ã‚Œã‚‹
        assert "ğŸ˜­" in surfaces1

        # ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒ¬ã‚¯ã‚¿å˜ä½“ã¯é™¤å¤–ã•ã‚Œã‚‹
        # ï¼ˆçµµæ–‡å­—æœ¬ä½“ã¯æŠ½å‡ºã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰
        assert "\ufe0f" not in surfaces2

    def test_only_control_characters_returns_empty(self) -> None:
        """åˆ¶å¾¡æ–‡å­—ã®ã¿ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ç©ºã®ãƒªã‚¹ãƒˆã‚’è¿”ã™ã“ã¨ã‚’ç¢ºèª"""
        analyzer = MorphologicalAnalyzer(min_length=1)

        test_cases = [
            "\ufe0f",  # ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒ¬ã‚¯ã‚¿
            "\u200d",  # ã‚¼ãƒ­å¹…æ¥åˆå­
            "\u3000",  # å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹
            "\ufe0f\u200d",  # è¤‡æ•°ã®åˆ¶å¾¡æ–‡å­—
            "\u3000\u3000",  # è¤‡æ•°ã®å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹
        ]

        for text in test_cases:
            words = analyzer.analyze(text)
            assert len(words) == 0, f"åˆ¶å¾¡æ–‡å­— {repr(text)} ãŒé™¤å¤–ã•ã‚Œã¦ã„ã¾ã›ã‚“"


class TestNounBaseForm:
    """åè©ã®åŸºæœ¬å½¢å‡¦ç†ã®ãƒ†ã‚¹ãƒˆ

    åè©ã«ã¯æ´»ç”¨ãŒãªã„ãŸã‚ã€åŸºæœ¬å½¢ã§ã¯ãªãè¡¨å±¤å½¢ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
    """

    def test_proper_noun_uses_surface_form(self) -> None:
        """å›ºæœ‰åè©ã¯åŸºæœ¬å½¢ã§ã¯ãªãè¡¨å±¤å½¢ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª

        neologdè¾æ›¸ã¯ã€Œã‚¢ã‚ªã€ã‚’åŸºæœ¬å½¢ã€ŒA-Oã€ã«å¤‰æ›ã™ã‚‹ãŒã€è¡¨å±¤å½¢ã‚’ä½¿ã†ã¹ã
        """
        analyzer = MorphologicalAnalyzer(min_length=1)

        # ã€Œã‚¢ã‚ªã®ãƒã‚³ã€ã¨ã„ã†ãƒãƒ³ã‚¬ã‚¿ã‚¤ãƒˆãƒ«ã‚’å«ã‚€æ–‡
        # neologdè¾æ›¸ã¯ã€Œã‚¢ã‚ªã€ã‚’åŸºæœ¬å½¢ã€ŒA-Oã€ã«å¤‰æ›ã™ã‚‹ãŒã€è¡¨å±¤å½¢ã‚’ä½¿ã†ã¹ã
        words = analyzer.analyze("ã‚¢ã‚ªã®ãƒã‚³ã‚’èª­ã‚“ã ")

        # ã€Œã‚¢ã‚ªã€ã¨ã„ã†å›ºæœ‰åè©ãŒæŠ½å‡ºã•ã‚Œã‚‹ã¯ãš
        surfaces = [w.surface for w in words]
        base_forms = [w.base_form for w in words]

        # è¡¨å±¤å½¢ã«ã€Œã‚¢ã‚ªã€ãŒå«ã¾ã‚Œã‚‹
        assert "ã‚¢ã‚ª" in surfaces, f"ã€Œã‚¢ã‚ªã€ãŒè¡¨å±¤å½¢ã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“: {surfaces}"

        # åŸºæœ¬å½¢ã‚‚ã€Œã‚¢ã‚ªã€ã§ã‚ã‚‹ã¹ãï¼ˆã€ŒA-Oã€ã§ã¯ãªã„ï¼‰
        assert "ã‚¢ã‚ª" in base_forms, f"åŸºæœ¬å½¢ãŒã€Œã‚¢ã‚ªã€ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {base_forms}"
        assert "A-O" not in base_forms, f"åŸºæœ¬å½¢ã«ã€ŒA-Oã€ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {base_forms}"

    def test_multiple_proper_nouns(self) -> None:
        """è¤‡æ•°ã®å›ºæœ‰åè©ãŒã™ã¹ã¦è¡¨å±¤å½¢ã§å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        analyzer = MorphologicalAnalyzer(min_length=1)

        words = analyzer.analyze("ã‚¢ã‚ªã¨ãƒã‚³ã¯å‹é”ã§ã™")

        base_forms = [w.base_form for w in words]

        # ä¸¡æ–¹ã¨ã‚‚è¡¨å±¤å½¢ã®ã¾ã¾
        assert "ã‚¢ã‚ª" in base_forms
        assert "ãƒã‚³" in base_forms
        # å¤‰æ›ã•ã‚ŒãŸå½¢ãŒå«ã¾ã‚Œã¦ã„ãªã„
        assert "A-O" not in base_forms

    def test_proper_noun_combined_with_other_words(self) -> None:
        """å›ºæœ‰åè©ã¨ä»–ã®å“è©ãŒæ··åœ¨ã™ã‚‹æ–‡ã§ã®å‡¦ç†ç¢ºèª"""
        analyzer = MorphologicalAnalyzer(min_length=2)

        # ã€Œå°‘å¹´ã‚¸ãƒ£ãƒ³ãƒ—ï¼‹ã€ã§ã€Œã‚¢ã‚ªã®ãƒã‚³ã€ã‚’èª­ã‚€
        words = analyzer.analyze("å°‘å¹´ã‚¸ãƒ£ãƒ³ãƒ—ï¼‹ã§ã‚¢ã‚ªã®ãƒã‚³ã‚’èª­ã‚“ã ")

        base_forms = [w.base_form for w in words]
        surfaces = [w.surface for w in words]

        # å›ºæœ‰åè©ã¯è¡¨å±¤å½¢
        assert "ã‚¢ã‚ª" in surfaces or "ã‚¢ã‚ª" in base_forms
        assert "A-O" not in base_forms

    def test_general_noun_still_uses_base_form(self) -> None:
        """ä¸€èˆ¬åè©ã¯å¼•ãç¶šãåŸºæœ¬å½¢ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        analyzer = MorphologicalAnalyzer(min_length=1)

        # æ´»ç”¨ã®ã‚ã‚‹ä¸€èˆ¬çš„ãªæ–‡
        # â€»ãŸã ã—ã€åè©è‡ªä½“ã«æ´»ç”¨ã¯ãªã„ãŸã‚ã€åŸºæœ¬å½¢=è¡¨å±¤å½¢ã®ã‚±ãƒ¼ã‚¹ãŒå¤šã„
        words = analyzer.analyze("æœ¬ã‚’èª­ã‚€")

        # ã€Œæœ¬ã€ã¯ä¸€èˆ¬åè©ãªã®ã§åŸºæœ¬å½¢ãŒä½¿ã‚ã‚Œã‚‹
        hon_words = [w for w in words if w.surface == "æœ¬"]
        assert len(hon_words) > 0
        assert hon_words[0].base_form == "æœ¬"  # åè©ãªã®ã§åŸºæœ¬å½¢=è¡¨å±¤å½¢
