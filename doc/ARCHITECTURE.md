# システムアーキテクチャ

## アーキテクチャ概要

```
[フロントエンド] ←→ [FastAPI] ←→ [LINEトーク解析エンジン]
                                        ↓
                                   [形態素解析(MeCab)]
```

## レイヤー構成

```
├── API Layer (FastAPI)
│   ├── エンドポイント定義
│   ├── リクエスト/レスポンス検証
│   └── CORS設定
│
├── Service Layer
│   ├── TalkAnalyzer（統合解析サービス）
│   ├── LineMessageParser（パーサー）
│   ├── MorphologicalAnalyzer（形態素解析）
│   ├── WordCounter（単語カウンター）
│   └── DemoService（デモモード）
│
└── Data Layer
    ├── ストップワード辞書（stopwords.json）
    └── デモレスポンス（demo_response.json）
```

## 解析処理の詳細

### 1. LINEトーク履歴パーサー (`services/parser.py`)

**責務**:
- LINEトーク履歴ファイルを読み込み、構造化データに変換

**処理フロー**:
1. テキストファイルを読み込み、ヘッダーと保存日時行をスキップ
2. 行ごとに読み込み
3. 日付行（`YYYY/MM/DD(曜日)`形式）を検出して現在の日付を更新
4. メッセージ行をタブ文字で分割して解析（時刻、ユーザー名、メッセージ本文）
5. システムメッセージ（ユーザー名が空）、画像（`[写真]`）、スタンプ（`[スタンプ]`）等は除外
6. マルチラインメッセージ（改行を含むメッセージ）に対応
7. 構造化データ（リスト）として返却

**データ構造**:
```python
@dataclass
class Message:
    datetime: datetime
    user: str
    content: str
```

**除外対象**:
詳細は[WORD_COUNT_RULE.md](WORD_COUNT_RULE.md)を参照してください。

### 2. 形態素解析サービス (`services/morphological.py`)

**責務**:
- MeCabを使用して単語に分解し、品詞情報を付与

**処理フロー**:
1. メッセージ本文をMeCabで形態素解析
2. 品詞情報を抽出
3. 品詞フィルタリング
4. 単語長フィルタリング
5. ストップワード辞書で除外
6. 単語リストを返却

**詳細なカウントルール**:
詳細は[WORD_COUNT_RULE.md](WORD_COUNT_RULE.md)を参照してください。

### 3. 単語カウンター (`services/word_counter.py`)

**責務**:
- 形態素解析結果とメッセージ全文の集計

#### 3.1 形態素解析結果のカウント

1. 各単語の出現回数を集計
2. 品詞情報を保持
3. 出現回数でフィルタリング

#### 3.2 メッセージ全文のカウント

1. 各メッセージを1単語として扱う
2. 完全一致でカウント
3. メッセージ長でフィルタリング
4. 出現回数でフィルタリング

**詳細なカウントルール**:
詳細は[WORD_COUNT_RULE.md](WORD_COUNT_RULE.md)を参照してください。

### 4. 統合解析サービス (`services/analyzer.py`)

**責務**:
- 上記サービスを統合し、API向けのレスポンスを生成

**処理フロー**:
1. パーサーでトーク履歴を構造化
2. 日付範囲フィルタ（start_date/end_dateが指定されている場合）
3. 形態素解析で単語抽出
4. 単語カウンターで集計
5. 上位N件を抽出してソート
6. 全体とユーザー別の両方を集計
7. APIレスポンス形式に整形

**出力データ**:
- 解析期間（start_date, end_date）
- 総メッセージ数
- 総ユーザー数
- 形態素解析結果（全体の上位N件）
- メッセージ解析結果（全体の上位N件）
- ユーザー別解析結果（各ユーザーの上位N件）

### 5. デモサービス (`services/demo_service.py`)

[DEMO.md](DEMO.md)を参照してください。
